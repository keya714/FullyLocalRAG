paths:
  pdf_dir: ./corpus
  index_dir: ./index

embedding:
  model_name: sentence-transformers/all-MiniLM-L6-v2
  device: cpu

chunking:
  chunk_size: 400
  chunk_overlap: 5

retrieval:
  # use_cross_encoder: true
  # cross_encoder_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  # top_k_rerank: 8
  top_k: 5
  strategy: hybrid        # dense | bm25 | hybrid (works if you used my hybrid retriever)
  bm25_weight: 0.5
  mmr: false
  min_context_chars: 800
  low_recall_threshold: 2

llm:
  model: "llama3.2"   # or any model you `ollama pull`
  n_ctx: 4096
  temperature: 0.4
  max_new_tokens: 512
  stop: []               # e.g., ["<|assistant|>", "</s>"]


guardrails:
  enabled: true
  blocked_topics:
    - self-harm
    - explicit_illegal_howto
    - malware
    - explosives
    - hate
  deny_message: >
    I can’t help with that topic. If you have another question, I’m happy to help with safe, allowed topics.

cli:
  pretty_print: true
  show_sources: true
  max_source_chars: 1000
